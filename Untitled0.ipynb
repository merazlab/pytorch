{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled0.ipynb","provenance":[],"authorship_tag":"ABX9TyOm2HA6bJjRdyzzAvWcexKD"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"LROsmt0JgD_u","colab_type":"code","colab":{}},"source":["import torch"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RoChl9vwg2i_","colab_type":"code","colab":{}},"source":["# create a simple sequential network (`nn.Module` object) from layers (other `nn.Module` objects)\n","net = torch.nn.Sequential(\n","    torch.nn.Linear(28*28,256),\n","    torch.nn.Sigmoid(),\n","    torch.nn.Linear(256,10))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"a-SLr5pBg93Y","colab_type":"code","colab":{}},"source":["# create a more customizable network module\n","class MyNetwork(torch.nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.layer1 = torch.nn.Linear(28*28,256)\n","        self.layer2 = torch.nn.Sigmoid()\n","        self.layer3 = torch.nn.Linear(256,10)\n","\n","    def forward(self, input_val):\n","        h = input_val\n","        h = self.layer1(h)\n","        h = self.layer2(h)\n","        h = self.layer3(h)\n","        return h\n","\n","net = MyNetwork()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ip_DY5sUjwNa","colab_type":"text"},"source":["Saving or loding"]},{"cell_type":"code","metadata":{"id":"XXoW_Z55jvP8","colab_type":"code","outputId":"e2bc087a-2320-4498-e85f-644d056a2a8a","executionInfo":{"status":"ok","timestamp":1585825400902,"user_tz":-330,"elapsed":977,"user":{"displayName":"Md Meraz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCDqeiThy6Uz7npH4ERYGnqSgnpBR6l78yLv1B=s64","userId":"16501587712343191977"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# get dictionary of keys to weights using `state_dict`\n","net = torch.nn.Sequential(\n","    torch.nn.Linear(28*28,256),\n","    torch.nn.Sigmoid(),\n","    torch.nn.Linear(256,10))\n","print(net.state_dict().keys())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["odict_keys(['0.weight', '0.bias', '2.weight', '2.bias'])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tG59AGhuj0QS","colab_type":"code","outputId":"763f4839-c980-4489-96cf-f49437f0cc04","executionInfo":{"status":"ok","timestamp":1585825478127,"user_tz":-330,"elapsed":1129,"user":{"displayName":"Md Meraz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCDqeiThy6Uz7npH4ERYGnqSgnpBR6l78yLv1B=s64","userId":"16501587712343191977"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# save a dictionary\n","torch.save(net.state_dict(),'test.t7')\n","# load a dictionary\n","net.load_state_dict(torch.load('test.t7'))"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"d3rX3nAMkHEj","colab_type":"code","colab":{}},"source":["import numpy as np\n","import torch\n","import torch.utils.data\n","\n","\n","class OnesCounter(torch.nn.Module):\n","    def __init__(self, input_size):\n","        super().__init__()\n","        self.input_size = input_size\n","\n","        count_bitwidth = int(np.ceil(np.log2(input_size + 1)))\n","        self.to_hidden1 = torch.nn.Linear(input_size, 2 * input_size)\n","        self.hidden_sigmoid1 = torch.nn.Sigmoid()\n","        self.to_hidden2 = torch.nn.Linear(2 * input_size, 2 * input_size)\n","        self.hidden_sigmoid2 = torch.nn.Sigmoid()\n","        self.to_binary = torch.nn.Linear(2 * input_size, count_bitwidth)\n","\n","    def forward(self, input_val):\n","        hidden1 = self.hidden_sigmoid1(self.to_hidden1(input_val))\n","        hidden2 = self.hidden_sigmoid2(self.to_hidden2(hidden1))\n","        return self.to_binary(hidden2)\n","\n","\n","def load_data():\n","    # We'll just make our data on the spot here, but\n","    # we usually load real data sets from a file\n","\n","    # Create 10000 random 7-bit inputs\n","    data = np.random.binomial(1, 0.5, size=(10000, 7))\n","\n","    # Count the number of 1's in each input\n","    labels = data.sum(axis=1)\n","\n","    # Create the binary encoding of the ground truth labels\n","    # As a bit of practice using Numpy, we're going to do this\n","    # without using a Python loop.\n","    labels_binary = np.unpackbits(labels.astype(np.uint8)).reshape((-1,8))\n","    labels_binary = labels_binary[:,-3:]\n","\n","    return (data, labels_binary)\n","\n","\n","def to_tensor(numpy_array):\n","    # Numpy array -> Tensor\n","    return torch.from_numpy(numpy_array).float()\n","\n","\n","def to_variable(tensor):\n","    # Tensor -> Variable (on GPU if possible)\n","    if torch.cuda.is_available():\n","        # Tensor -> GPU Tensor\n","        tensor = tensor.cuda()\n","    return torch.autograd.Variable(tensor)\n","\n","\n","def training_routine(num_epochs, minibatch_size, learn_rate):\n","    (data, labels_binary) = load_data()\n","\n","    my_net = OnesCounter(7)  # Create the network,\n","    loss_fn = torch.nn.BCEWithLogitsLoss()  # and choose the loss function / optimizer\n","    optim = torch.optim.SGD(my_net.parameters(), lr=learn_rate)\n","\n","    if torch.cuda.is_available():\n","        # Move the network and the optimizer to the GPU\n","        my_net = my_net.cuda()\n","        loss_fn = loss_fn.cuda()\n","\n","    dataset = torch.utils.data.TensorDataset(\n","        to_tensor(data), to_tensor(labels_binary))\n","    data_loader = torch.utils.data.DataLoader(\n","        dataset, batch_size=minibatch_size, shuffle=True)\n","\n","    for epoch in range(num_epochs):\n","        losses = []\n","        for (input_val, label) in data_loader:\n","            optim.zero_grad()  # Reset the gradients\n","\n","            prediction = my_net(to_variable(input_val))  # Feed forward\n","            loss = loss_fn(prediction, to_variable(label))  # Compute losses\n","            loss.backward()  # Backpropagate the gradients\n","            losses.append(loss.data.cpu().numpy())\n","            optim.step()  # Update the network\n","        print(\"Epoch {} Loss: {:.4f}\".format(epoch, np.asscalar(np.mean(losses))))\n","    return my_net\n","\n","if __name__ == '__main__':\n","    net = training_routine(100, 50, 2)\n","    x = to_variable(to_tensor(np.array([[1,0,1,1,0,1,0], [0,1,0,0,0,0,0], [1,1,1,0,0,0,0]])))\n","    y = net(x)\n","    print('X: {}'.format(x.data.cpu().numpy()))\n","    print('Y (logits): {}'.format(y.data.cpu().numpy()))\n","    print('Y (argmax): {}'.format(y.data.cpu().numpy() > 0))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wI1JYL2yvBTB","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-QKAepuTvDIQ","colab_type":"code","colab":{}},"source":["model = nn.Linear(1, 1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"p4hoX7618NJ8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"63760017-97cd-44a1-a13c-67e4b788a7b8","executionInfo":{"status":"ok","timestamp":1585915687761,"user_tz":-330,"elapsed":1075,"user":{"displayName":"Md Meraz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCDqeiThy6Uz7npH4ERYGnqSgnpBR6l78yLv1B=s64","userId":"16501587712343191977"}}},"source":["print(model)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Linear(in_features=1, out_features=1, bias=True)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iCq0tJ-F8OwC","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}